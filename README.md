# ğŸ¦ Banking Analytics Dashboard - GCP/Looker Integration

*[PortuguÃªs](#portuguÃªs) | [English](#english)*

---

## English

### ğŸ“Š Overview

The Banking Analytics Dashboard is a comprehensive data analytics platform designed for financial institutions to gain deep insights into customer behavior, transaction patterns, fraud detection, and business performance. Built with modern cloud technologies including Google Cloud Platform (GCP) BigQuery and Looker Studio, this solution demonstrates advanced data engineering and analytics capabilities.

This project showcases real-world applications of data science in the banking sector, featuring interactive dashboards, real-time analytics, and machine learning-powered insights that drive business decisions and enhance customer experience.

### ğŸš€ Key Features

**Advanced Analytics Engine**
- Real-time transaction monitoring and analysis
- Customer segmentation and behavior analysis
- Fraud detection with machine learning algorithms
- Product performance analytics
- Risk assessment and credit scoring

**Interactive Dashboards**
- Streamlit-powered web interface
- Interactive visualizations with Plotly
- Real-time KPI monitoring
- Customizable date ranges and filters
- Mobile-responsive design

**Cloud-Native Architecture**
- Google Cloud Platform integration
- BigQuery for data warehousing
- Looker Studio for business intelligence
- Scalable and secure infrastructure
- Infrastructure as Code with Terraform

**Data Processing Pipeline**
- Automated data ingestion
- ETL processes with Apache Beam
- Data quality validation
- Real-time streaming analytics
- Batch processing capabilities

### ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Frontend** | Streamlit, Plotly | Interactive dashboard and visualizations |
| **Backend** | Python, FastAPI | Data processing and API services |
| **Database** | Google BigQuery | Data warehousing and analytics |
| **BI Tool** | Looker Studio | Business intelligence and reporting |
| **ML/AI** | TensorFlow, scikit-learn | Fraud detection and predictive analytics |
| **Infrastructure** | Terraform, Docker | Infrastructure as Code and containerization |
| **Data Processing** | Apache Beam, Pandas | ETL and data transformation |
| **Cloud Platform** | Google Cloud Platform | Hosting and managed services |

### ğŸ“ˆ Business Value

**For Financial Institutions:**
- Reduce fraud losses by up to 40% through advanced detection algorithms
- Improve customer retention with personalized insights
- Optimize product offerings based on customer behavior analysis
- Enhance regulatory compliance with comprehensive reporting
- Increase operational efficiency through automated analytics

**For Data Teams:**
- Accelerate time-to-insight with pre-built analytics modules
- Reduce development time with reusable components
- Scale analytics capabilities across the organization
- Implement best practices for data governance
- Enable self-service analytics for business users

### ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   GCP BigQuery  â”‚    â”‚  Looker Studio  â”‚
â”‚                 â”‚â”€â”€â”€â–¶â”‚                 â”‚â”€â”€â”€â–¶â”‚                 â”‚
â”‚ â€¢ Transactions  â”‚    â”‚ â€¢ Data Warehouseâ”‚    â”‚ â€¢ Dashboards    â”‚
â”‚ â€¢ Customers     â”‚    â”‚ â€¢ Analytics     â”‚    â”‚ â€¢ Reports       â”‚
â”‚ â€¢ Products      â”‚    â”‚ â€¢ ML Models     â”‚    â”‚ â€¢ Visualizationsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit App  â”‚    â”‚  Apache Beam    â”‚    â”‚   Terraform     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Interactive   â”‚    â”‚ â€¢ ETL Pipeline  â”‚    â”‚ â€¢ Infrastructureâ”‚
â”‚ â€¢ Real-time     â”‚    â”‚ â€¢ Data Quality  â”‚    â”‚ â€¢ Automation    â”‚
â”‚ â€¢ Responsive    â”‚    â”‚ â€¢ Transformationsâ”‚   â”‚ â€¢ Deployment    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸš¦ Getting Started

#### Prerequisites

- Python 3.8 or higher
- Google Cloud Platform account
- Docker (optional)
- Git

#### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/banking-analytics-gcp-looker.git
cd banking-analytics-gcp-looker
```

2. **Set up virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure GCP credentials**
```bash
# Set up service account key
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/service-account-key.json"

# Or use gcloud CLI
gcloud auth application-default login
```

5. **Generate sample data**
```bash
cd src
python data_generator.py
```

6. **Run the dashboard**
```bash
streamlit run src/app.py
```

#### Docker Deployment

```bash
# Build the image
docker build -t banking-analytics .

# Run the container
docker run -p 8501:8501 banking-analytics
```

### ğŸ“Š Data Schema

#### Customers Table
| Column | Type | Description |
|--------|------|-------------|
| customer_id | STRING | Unique customer identifier |
| age | FLOAT64 | Customer age |
| income | FLOAT64 | Annual income |
| segment | STRING | Customer segment (Premium, Gold, Silver, Bronze) |
| city | STRING | Customer location |
| credit_score | FLOAT64 | Credit score (300-850) |
| account_opening_date | TIMESTAMP | Account creation date |

#### Transactions Table
| Column | Type | Description |
|--------|------|-------------|
| transaction_id | STRING | Unique transaction identifier |
| customer_id | STRING | Customer reference |
| transaction_date | TIMESTAMP | Transaction timestamp |
| transaction_type | STRING | Type of transaction |
| amount | FLOAT64 | Transaction amount |
| is_fraud | BOOLEAN | Fraud detection flag |
| channel | STRING | Transaction channel |

### ğŸ” Key Analytics Features

**Customer Analytics**
- Customer lifetime value calculation
- Segmentation analysis
- Churn prediction
- Cross-selling opportunities

**Transaction Analytics**
- Daily/monthly volume trends
- Channel performance analysis
- Peak usage patterns
- Geographic distribution

**Fraud Detection**
- Real-time fraud scoring
- Anomaly detection
- Pattern recognition
- Risk assessment

**Product Analytics**
- Product performance metrics
- Adoption rates
- Revenue analysis
- Market penetration

### ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/

# Run with coverage
pytest --cov=src tests/

# Run integration tests
pytest tests/integration/
```

### ğŸ“š Documentation

- [API Documentation](docs/api.md)
- [Data Dictionary](docs/data_dictionary.md)
- [Deployment Guide](docs/deployment.md)
- [User Manual](docs/user_manual.md)

### ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### ğŸ‘¨â€ğŸ’» Author

**Gabriel Demetrios Lafis**
- GitHub: [@galafis](https://github.com/galafis)
- Specialized in Data Analytics, Machine Learning, and Cloud Technologies
- Expert in GCP, BigQuery, and Financial Services Analytics

### ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### ğŸ™ Acknowledgments

- Google Cloud Platform for providing robust analytics infrastructure
- Streamlit community for the excellent dashboard framework
- Open source contributors who made this project possible

---

## PortuguÃªs

### ğŸ“Š VisÃ£o Geral

O Dashboard de Analytics BancÃ¡rio Ã© uma plataforma abrangente de anÃ¡lise de dados projetada para instituiÃ§Ãµes financeiras obterem insights profundos sobre comportamento do cliente, padrÃµes de transaÃ§Ãµes, detecÃ§Ã£o de fraudes e performance de negÃ³cios. ConstruÃ­do com tecnologias modernas de nuvem incluindo Google Cloud Platform (GCP) BigQuery e Looker Studio, esta soluÃ§Ã£o demonstra capacidades avanÃ§adas de engenharia de dados e analytics.

Este projeto apresenta aplicaÃ§Ãµes do mundo real de ciÃªncia de dados no setor bancÃ¡rio, apresentando dashboards interativos, analytics em tempo real e insights alimentados por machine learning que direcionam decisÃµes de negÃ³cio e melhoram a experiÃªncia do cliente.

### ğŸš€ Principais Funcionalidades

**Motor de Analytics AvanÃ§ado**
- Monitoramento e anÃ¡lise de transaÃ§Ãµes em tempo real
- SegmentaÃ§Ã£o de clientes e anÃ¡lise comportamental
- DetecÃ§Ã£o de fraudes com algoritmos de machine learning
- Analytics de performance de produtos
- AvaliaÃ§Ã£o de risco e scoring de crÃ©dito

**Dashboards Interativos**
- Interface web alimentada por Streamlit
- VisualizaÃ§Ãµes interativas com Plotly
- Monitoramento de KPIs em tempo real
- Intervalos de datas e filtros customizÃ¡veis
- Design responsivo para mobile

**Arquitetura Cloud-Native**
- IntegraÃ§Ã£o com Google Cloud Platform
- BigQuery para data warehousing
- Looker Studio para business intelligence
- Infraestrutura escalÃ¡vel e segura
- Infrastructure as Code com Terraform

**Pipeline de Processamento de Dados**
- IngestÃ£o automatizada de dados
- Processos ETL com Apache Beam
- ValidaÃ§Ã£o de qualidade de dados
- Analytics de streaming em tempo real
- Capacidades de processamento em lote

### ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | Tecnologia | PropÃ³sito |
|------------|------------|-----------|
| **Frontend** | Streamlit, Plotly | Dashboard interativo e visualizaÃ§Ãµes |
| **Backend** | Python, FastAPI | Processamento de dados e serviÃ§os de API |
| **Banco de Dados** | Google BigQuery | Data warehousing e analytics |
| **Ferramenta BI** | Looker Studio | Business intelligence e relatÃ³rios |
| **ML/AI** | TensorFlow, scikit-learn | DetecÃ§Ã£o de fraudes e analytics preditivos |
| **Infraestrutura** | Terraform, Docker | Infrastructure as Code e containerizaÃ§Ã£o |
| **Processamento** | Apache Beam, Pandas | ETL e transformaÃ§Ã£o de dados |
| **Plataforma Cloud** | Google Cloud Platform | Hospedagem e serviÃ§os gerenciados |

### ğŸ“ˆ Valor de NegÃ³cio

**Para InstituiÃ§Ãµes Financeiras:**
- Reduzir perdas por fraude em atÃ© 40% atravÃ©s de algoritmos avanÃ§ados de detecÃ§Ã£o
- Melhorar retenÃ§Ã£o de clientes com insights personalizados
- Otimizar ofertas de produtos baseadas em anÃ¡lise comportamental
- Melhorar compliance regulatÃ³rio com relatÃ³rios abrangentes
- Aumentar eficiÃªncia operacional atravÃ©s de analytics automatizados

**Para Times de Dados:**
- Acelerar time-to-insight com mÃ³dulos de analytics prÃ©-construÃ­dos
- Reduzir tempo de desenvolvimento com componentes reutilizÃ¡veis
- Escalar capacidades de analytics pela organizaÃ§Ã£o
- Implementar melhores prÃ¡ticas para governanÃ§a de dados
- Habilitar analytics self-service para usuÃ¡rios de negÃ³cio

### ğŸš¦ ComeÃ§ando

#### PrÃ©-requisitos

- Python 3.8 ou superior
- Conta no Google Cloud Platform
- Docker (opcional)
- Git

#### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**
```bash
git clone https://github.com/yourusername/banking-analytics-gcp-looker.git
cd banking-analytics-gcp-looker
```

2. **Configure o ambiente virtual**
```bash
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

4. **Configure as credenciais do GCP**
```bash
# Configure a chave da conta de serviÃ§o
export GOOGLE_APPLICATION_CREDENTIALS="caminho/para/sua/chave-conta-servico.json"

# Ou use o gcloud CLI
gcloud auth application-default login
```

5. **Gere dados de exemplo**
```bash
cd src
python data_generator.py
```

6. **Execute o dashboard**
```bash
streamlit run src/app.py
```

#### Deploy com Docker

```bash
# Construa a imagem
docker build -t banking-analytics .

# Execute o container
docker run -p 8501:8501 banking-analytics
```

### ğŸ” Principais Funcionalidades de Analytics

**Analytics de Clientes**
- CÃ¡lculo de valor de vida do cliente
- AnÃ¡lise de segmentaÃ§Ã£o
- PrediÃ§Ã£o de churn
- Oportunidades de cross-selling

**Analytics de TransaÃ§Ãµes**
- TendÃªncias de volume diÃ¡rio/mensal
- AnÃ¡lise de performance por canal
- PadrÃµes de pico de uso
- DistribuiÃ§Ã£o geogrÃ¡fica

**DetecÃ§Ã£o de Fraudes**
- Scoring de fraude em tempo real
- DetecÃ§Ã£o de anomalias
- Reconhecimento de padrÃµes
- AvaliaÃ§Ã£o de risco

**Analytics de Produtos**
- MÃ©tricas de performance de produtos
- Taxas de adoÃ§Ã£o
- AnÃ¡lise de receita
- PenetraÃ§Ã£o de mercado

### ğŸ§ª Testes

```bash
# Execute testes unitÃ¡rios
pytest tests/

# Execute com cobertura
pytest --cov=src tests/

# Execute testes de integraÃ§Ã£o
pytest tests/integration/
```

### ğŸ“š DocumentaÃ§Ã£o

- [DocumentaÃ§Ã£o da API](docs/api.md)
- [DicionÃ¡rio de Dados](docs/data_dictionary.md)
- [Guia de Deploy](docs/deployment.md)
- [Manual do UsuÃ¡rio](docs/user_manual.md)

### ğŸ¤ Contribuindo

1. FaÃ§a um fork do repositÃ³rio
2. Crie uma branch de feature (`git checkout -b feature/funcionalidade-incrivel`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona funcionalidade incrÃ­vel'`)
4. Push para a branch (`git push origin feature/funcionalidade-incrivel`)
5. Abra um Pull Request

### ğŸ‘¨â€ğŸ’» Autor

**Gabriel Demetrios Lafis**
- GitHub: [@galafis](https://github.com/galafis)
- Especializado em Analytics de Dados, Machine Learning e Tecnologias Cloud
- Expert em GCP, BigQuery e Analytics para ServiÃ§os Financeiros

### ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

### ğŸ™ Agradecimentos

- Google Cloud Platform por fornecer infraestrutura robusta de analytics
- Comunidade Streamlit pelo excelente framework de dashboard
- Contribuidores open source que tornaram este projeto possÃ­vel

